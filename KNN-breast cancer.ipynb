{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors algorithm for classification\n",
    "\n",
    "Here I'll be constructing the K-Nearest Neighbor (KNN) algorithm from scratch to make a classification. At the end, I'll also see how to use the library from scikit-learn to implement KNN.\n",
    "\n",
    "### Overview\n",
    "\n",
    "I'll use a data set to classify whether a patience have breast cancer os not given some features.\n",
    "\n",
    "### The data\n",
    "\n",
    "I'll be using the data kindly provided by UCI Machine Learning Repository that can be found here:https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29 or here: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "The data consist of 569 samples and 30 features with a binary target named with 'M', that stands for malignant (the patience have cancer) and 'B', that stands for benign (the pacience does not have a harmful cancer).\n",
    "\n",
    "### Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and cleaning the data\n",
    "\n",
    "Having the data downloaded in a .csv file, let's take see how the data looks. Remembering to import the desired libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target column is the second columns. Let's pop that column to a new variable, and then substitute the labels 'M' for 1 and 'B' for 0. Also, seems like the last columns is not wanted. Let's get rid of the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
      "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.columns[-1], axis=1, inplace=True)\n",
    "target = df.pop('diagnosis')\n",
    "# target = target.apply(lambda x: 1 if x == 'M' else 0)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    357\n",
      "M    212\n",
      "Name: diagnosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if  there is any missing value in our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has no missing values\n"
     ]
    }
   ],
   "source": [
    "if df.isna().any().any():\n",
    "    print('Seems like there are some missing values in the dataset')\n",
    "    print('There are {} missing values'.format(df.isna().sum().sum()))\n",
    "else: \n",
    "    print('The data has no missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, there is no missing values in our data set! Now we shall proceed with the KNN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances\n",
    "\n",
    "The KNN algorithm is all about finding distances of an object from its neighbors. Let's write some functions to compute commonly used distances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "\n",
    "Probably the most well known distance. For more information about Euclidean distance, check: https://en.wikipedia.org/wiki/Euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(pt1, pt2):\n",
    "  '''\n",
    "  This function takes two lists as parameters and computes the Euclidean distance between the two objects.\n",
    "  Each element in a list represents one coordinate of the respective vector. \n",
    "  \n",
    "  Returns a number representing the distance between the two vectors given as arguments\n",
    "  '''\n",
    "  return sum([(a - b) ** 2 for [a, b] in zip(pt1, pt2)]) ** 0.5\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan distance\n",
    "\n",
    "Very similar to the Euclidean distance. However, instead of summing the squared difference between the coordinates of the vector, we sum the absolute diference between the coordinates. For more information about the Manhattan distance, check: https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "\n",
    "P.S.: in scikit-learn, the Manhattan distance is refered as cityblock distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(pt1, pt2):\n",
    "  '''\n",
    "  This function takes two lists as parameters and computes the Manhattan distance between the two objects.\n",
    "  Each element in a list represents one coordinate of the respective vector. \n",
    "  \n",
    "  Returns a number representing the distance between the two vectors given as arguments\n",
    "  '''\n",
    "  return sum([abs(a - b) for [a, b] in zip(pt1, pt2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming distance\n",
    "\n",
    "Another formula to calculate distances. The Hamming distance cares only about if the coordinates of two vectors are the same. The hamming distance adds one to every similar coordinates shared by two vectors. The Hamming distance is usualy used to check spelling. For more information about the Hamming distance, check: https://en.wikipedia.org/wiki/Hamming_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(pt1, pt2):\n",
    "  '''\n",
    "  This function takes two lists as parameters and computes the Hamming distance between the two objects. \n",
    "  \n",
    "  Returns a number representing the distance between the two vectors given as arguments\n",
    "  '''\n",
    "  return sum([1 if a != b else 0 for [a, b] in zip(pt1, pt2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "It is of major inportance to normalize the features in order to use the KNN algorithm. We will be exploring two kinds of normalization, viz. the min-max normalization and the z-score normalization. \n",
    "\n",
    "It is up to you to decide which kind of normalization is best suited for your application. In a nutshell, the min-max normalization will scale all features to the same scale, however it does not perform nicely with outliers; the z-score normalization can handle better outliers, however it may not normalize all features to the same scale\n",
    "\n",
    "For more information about the normalization explored here, check: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(lst):\n",
    "  '''\n",
    "  This function take a list as a parameter and returns a list with the normalized values based on the Min-Max \n",
    "  normalization\n",
    "  '''\n",
    "  maximum, minimum = max(lst), min(lst)\n",
    "  return [(i-minimum)/(maximum - minimum) for i in lst]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(lst):\n",
    "  '''\n",
    "  This function ake a list as a parameter and returns a list with the normalized values based on the Z-score \n",
    "  normalization\n",
    "  '''\n",
    "  mean, sig = np.mean(lst), np.std(lst)\n",
    "  return [ (i - mean) / sig for i in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN algorithm \n",
    "\n",
    "For more information about the k-nearest neighbors algorithm, check: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the features and normalizing\n",
    "\n",
    "We are going to use only 10 features out of the 30. Let's choose the columns that represents the features's mean and save that to a variable called features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   fractal_dimension_mean  \n",
      "0                 0.07871  \n",
      "1                 0.05667  \n",
      "2                 0.05999  \n",
      "3                 0.09744  \n",
      "4                 0.05883  \n"
     ]
    }
   ],
   "source": [
    "features = df[df.columns[1:11]]\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's normalize all columns with the min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
      "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
      "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
      "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
      "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          0.792037        0.703140             0.731113       0.686364   \n",
      "1          0.181768        0.203608             0.348757       0.379798   \n",
      "2          0.431017        0.462512             0.635686       0.509596   \n",
      "3          0.811361        0.565604             0.522863       0.776263   \n",
      "4          0.347893        0.463918             0.518390       0.378283   \n",
      "\n",
      "   fractal_dimension_mean  \n",
      "0                0.605518  \n",
      "1                0.141323  \n",
      "2                0.211247  \n",
      "3                1.000000  \n",
      "4                0.186816  \n"
     ]
    }
   ],
   "source": [
    "features = features.apply(min_max_normalize)\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our features are normalized. Nice! Now we are ready to calculate distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data\n",
    "\n",
    "Here we are going to use the scikit-learn function to split our data into train and test data. We will use 1/3 of our data for the test. \n",
    "\n",
    "For more information about this function, check: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the k nearest neighbors\n",
    "\n",
    "Here we will use one of the distance functions to find the k nearest neighbors.\n",
    "\n",
    "Remember that each row in our dataset represents one element. For instance, lets see how the first instance from our test set looks like. We take the first row in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius_mean               0.259785\n",
      "texture_mean              0.300643\n",
      "perimeter_mean            0.257757\n",
      "area_mean                 0.143542\n",
      "smoothness_mean           0.424483\n",
      "compactness_mean          0.265076\n",
      "concavity_mean            0.187559\n",
      "concave points_mean       0.189911\n",
      "symmetry_mean             0.436869\n",
      "fractal_dimension_mean    0.290017\n",
      "Name: 204, dtype: float64\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "first = X_test.iloc[0]\n",
    "first_label = y_test.iloc[0]\n",
    "print(first)\n",
    "print(first_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function that, given one instance, will return the k nearest neighbors from our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors(unknown, train_set, k, distance_fun):\n",
    "    '''\n",
    "    This function will return a list of lists. Each element of a list (namely, another list), have 2 elements: \n",
    "    the distance between the elements and the index of the respective element from the training set. \n",
    "    \n",
    "    For exemple: we will feed the function with one point (variable 'unknown'). The function will then calculate the \n",
    "    distance from 'unknown' to all of the items in the training set. In the for loop, a list 'neighbors' will be created\n",
    "    with the distance from 'unknown' to the i-th row of the training set. Obviously, right after the for loop, \n",
    "    the list 'neighbors' is sorted by the indexes. But we want to sort by the distances! This is done with the \n",
    "    next instruction 'neighbors.sort()'\n",
    "    \n",
    "    The function will have as arguments:\n",
    "        -> unknown : the point from where I want to calculate the distance from it to all the other points from training set\n",
    "        -> train_set : the features from the training set\n",
    "        -> k : number of neighbors\n",
    "        -> fun : the function that calculates the distance, e.g. euclidean_distance(), etc\n",
    "    '''\n",
    "    neighbors = []\n",
    "    for i in range(len(train_set)):\n",
    "        neighbors.append([distance_fun(unknown, train_set.iloc[i]), i])\n",
    "    neighbors.sort()\n",
    "    return neighbors[:k]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For example, let's find the 10 closest neighbors from the first row of the test set. Obviously, the closest neighbor is himself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0], [0.1081129182465027, 21], [0.11842369504905956, 69], [0.14770267494741063, 42], [0.15322710632214903, 136], [0.15464416857743077, 48], [0.16405411386054794, 124], [0.17386576269374462, 91], [0.18063047224943024, 180], [0.18489976844394124, 60]]\n"
     ]
    }
   ],
   "source": [
    "print(k_neighbors(first, X_test, 10, euclidean_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the k neighbors, it's time to classify the point, viz. is he benign or malign?\n",
    "\n",
    "Let's see an example. lets find the 20 closest neighbors from our first case in y_test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216    B\n",
      "160    B\n",
      "383    B\n",
      "423    B\n",
      "200    B\n",
      "266    B\n",
      "515    B\n",
      "356    B\n",
      "154    B\n",
      "106    B\n",
      "340    B\n",
      "292    B\n",
      "301    B\n",
      "44     M\n",
      "502    B\n",
      "483    B\n",
      "99     M\n",
      "488    B\n",
      "143    B\n",
      "96     B\n",
      "Name: diagnosis, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# fetch the neighbors\n",
    "list_neighbors = k_neighbors(first, X_train, 20, euclidean_distance)\n",
    "# retrieve the indexes from the neighbors\n",
    "list_indexes = [item[1] for item in list_neighbors]\n",
    "# let's see the if the neighbors are majority benign or malign\n",
    "print(y_train.iloc[list_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the neighbors are benign. So, it's probably a good idea to classify him as benign.\n",
    "\n",
    "Let's write a function that will make that decision for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify (unknown, dataset, labels, k):\n",
    "    # let's get the k-neighbors from our unknown\n",
    "    neighbors = k_neighbors(unknown, dataset, k, euclidean_distance)\n",
    "    indexes = [item[1] for item in neighbors]\n",
    "    neighbors_labels = labels.iloc[indexes]\n",
    "    \n",
    "    num_M = len( [label for label in neighbors_labels if label == 'M'] )\n",
    "    num_B = len( [label for label in neighbors_labels if label == 'B'] )\n",
    "\n",
    "    # now that we have the number of benign and malign cases from the neighbors, we shall return\n",
    "    # 'B' if most of neighbors are benign and 'M' if most are Malign\n",
    "    # If num_B == num_M, then we return the label from the closest neighbor\n",
    "    if num_B > num_M:\n",
    "        return 'B', num_B, num_M\n",
    "    elif num_M > num_B:\n",
    "        return 'M', num_B, num_M\n",
    "    else: \n",
    "        return neighbors_labels.iloc[0], num_B, num_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We predicted that the case is benign, since we have 10 benign neighbors and 0 malign neighbors\n"
     ]
    }
   ],
   "source": [
    "predict, num_B, num_M = classify (first, X_train, y_train, 10)\n",
    "if predict == 'M':\n",
    "    prediction = 'malign'\n",
    "else:\n",
    "    prediction = 'benign'\n",
    "print('We predicted that the case is {}, since we have {} benign neighbors and {} malign neighbors'.format(prediction, num_B, num_M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We performed the KNN algorithm and predicted if the unknown case cancer is benign or malign!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is our KNN algorithm?\n",
    "\n",
    "Now it's time to test the accuracy of our algorithm. Let's see how many predictions are similar to the actual cases. We are going to test all cases that didn't participate in the training algoritm, namely the 'X_test' data set and their respective labels stored in 'y_test' \n",
    "\n",
    "Now, we would like to classify all of rows from X_test. For now, let's run the algorithm for 7 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = []\n",
    "for i in range(len(X_test)):\n",
    "    predict_labels.append(classify(X_test.iloc[i], X_train, y_train, 7)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of predictions, let's compare with the actual diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We correctly predicted 177 out of 188 with an accuracy of 94.1%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = sum( [1 if a == b else 0 for a, b in zip(predict_labels, y_test)] )\n",
    "correct_pct = correct_predictions / len(y_test)\n",
    "\n",
    "print('We correctly predicted {} out of {} with an accuracy of {:.1f}%'.format(correct_predictions, len(y_test), correct_pct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the best k?\n",
    "\n",
    "Choosing the best k neighbors will influence in how well our algorithm will perform. But how to chose the best number of neighbors? We can actually make a plot of accuracy X number of neighbors. This way we can see what will be the best k for our problem. Let's just do that. Run the next cell, but it might take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9e0749a69af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredict_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpredict_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcorrect_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1b41112f0ae4>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(unknown, dataset, labels, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# let's get the k-neighbors from our unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mneighbors_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fe372988a0d3>\u001b[0m in \u001b[0;36mk_neighbors\u001b[0;34m(unknown, train_set, k, distance_fun)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistance_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6b2641cbaf99>\u001b[0m in \u001b[0;36meuclidean_distance\u001b[0;34m(pt1, pt2)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   '''\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mrepr\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \"\"\"\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_formatting_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = range(1, 30)\n",
    "total = len(y_test)\n",
    "accuracy = []\n",
    "\n",
    "for num_neighbors in k:\n",
    "    predict_labels = []\n",
    "    for i in range(len(X_test)):\n",
    "        predict_labels.append(classify(X_test.iloc[i], X_train, y_train, num_neighbors)[0])\n",
    "    correct_predictions = sum( [1 if a == b else 0 for a, b in zip(predict_labels, y_test)] )\n",
    "    correct_pct = correct_predictions / total\n",
    "    accuracy.append(correct_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it takes several minutes to run the above cell, I'll save the result below and plot the desired graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = range(1, 30)\n",
    "accu_list = [0.925531914893617, 0.925531914893617, 0.9414893617021277, 0.9308510638297872, 0.9308510638297872, 0.9414893617021277, 0.9414893617021277, 0.9361702127659575, 0.9468085106382979, 0.9414893617021277, 0.9468085106382979, 0.9414893617021277, 0.9414893617021277, 0.9361702127659575, 0.9308510638297872, 0.9308510638297872, 0.9361702127659575, 0.9414893617021277, 0.9468085106382979, 0.9414893617021277, 0.9414893617021277, 0.9468085106382979, 0.9308510638297872, 0.9414893617021277, 0.9361702127659575, 0.9361702127659575, 0.9361702127659575, 0.9361702127659575, 0.9361702127659575]\n",
    "\n",
    "plt.plot(k, accu_list )\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we can get our best result with k = 9 neighbors. Other higher values might result in the same accuracy, but it will cost more computational efforts to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sci-kit learn library\n",
    "\n",
    "Using functions from sci-kit learn library will reduce a lot of work. \n",
    "\n",
    "For more information about KNN from sklearn library, check: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build our classifier. Note that we set the number of neighbors on the next line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already split our data, and have them already normalized (don't forget to normalize them), it's time to train the classifier. For that, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can take our predictions. Let's classify our first row from the test dataset(stored in first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([first]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, it classified correcly! The sklearn library has a method .score() to tell us how good is the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9468085106382979\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. You can play with the code. For instance, what will be the best number k for neighbors? Which function will be the best to calculate the distance? What method should you use to normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
